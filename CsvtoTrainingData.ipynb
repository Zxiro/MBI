{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the needed features seperated with space: close open rsv k d volume ma20 ma60\n",
      "Enter the close type: close\n",
      "Enter the desired  data span , d  for day  w  for week  m  for month: w\n",
      "           date  adj_close  close   high    low   open   volume         rsv  \\\n",
      "1    2004-02-12      48.54  48.59  49.26  48.40  48.50  8114000    0.000000   \n",
      "2    2004-02-13      49.41  49.46  49.47  48.60  48.61  6138000    0.000000   \n",
      "3    2004-02-16      49.17  49.20  49.46  49.04  49.46  4154000    0.000000   \n",
      "4    2004-02-17      49.40  49.50  49.50  49.16  49.21  4645000    0.000000   \n",
      "5    2004-02-18      49.53  49.53  49.70  49.32  49.55  4018000    0.000000   \n",
      "...         ...        ...    ...    ...    ...    ...      ...         ...   \n",
      "3912 2019-12-05      92.85  92.90  93.00  92.20  92.35  3441050   78.947368   \n",
      "3913 2019-12-06      92.95  93.05  93.50  92.75  93.30  3394433   86.842105   \n",
      "3914 2019-12-09      93.60  93.65  93.80  93.20  93.20  2912194  107.142857   \n",
      "3915 2019-12-10      93.00  93.00  93.40  92.80  93.40  5465431   66.666667   \n",
      "3916 2019-12-11      93.75  93.75  93.75  92.95  93.00  1936772   97.916667   \n",
      "\n",
      "              k          d    ma5     ma20       ma60  \n",
      "1      0.000000   0.000000   0.00   0.0000   0.000000  \n",
      "2      0.000000   0.000000   0.00   0.0000   0.000000  \n",
      "3      0.000000   0.000000   0.00   0.0000   0.000000  \n",
      "4      0.000000   0.000000   0.00   0.0000   0.000000  \n",
      "5      0.000000   0.000000  39.35   0.0000   0.000000  \n",
      "...         ...        ...    ...      ...        ...  \n",
      "3912  44.324317  41.420185  92.05  97.0375  90.030833  \n",
      "3913  58.496913  47.112428  92.04  97.0150  90.195833  \n",
      "3914  74.712228  56.312361  92.35  97.0250  90.355000  \n",
      "3915  72.030374  61.551699  92.67  97.0800  90.519167  \n",
      "3916  80.659138  67.920845  92.86  97.1725  90.679167  \n",
      "\n",
      "[3916 rows x 13 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stock0050  trainX   (2515, 8)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stock0050  testX   (840, 8)\n",
      "stock0050  trainY   (503,)\n",
      "stock0050  testY   (168,)\n"
     ]
    }
   ],
   "source": [
    "import datetime#import datetime module convert data to datetime64(ns)\n",
    "import numpy as np\n",
    "import pandas as pd#import pandas module(Better than csv module!)\n",
    "import os\n",
    "import glob\n",
    "import sklearn as sk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from statistics import mean\n",
    "\n",
    "def resha(x):\n",
    "    nptrain=np.array(x)\n",
    "    nptrain=np.reshape(nptrain,(nptrain.shape[0]*nptrain.shape[1], nptrain.shape[2]))\n",
    "    return nptrain\n",
    "    \n",
    "def save_np(x,y):\n",
    "    train_x,x_test,train_y,y_test = train_test_split(x,y,test_size=0.25,random_state=42)\n",
    "    stock_name=path[12:21]\n",
    "    scaler = sk.preprocessing.StandardScaler().fit(resha(train_x))  #  標準化後的數據 \n",
    "    train_x=sk.preprocessing.scale(resha(train_x),0) # normalize each feature\n",
    "    \n",
    "    Npdata=train_x\n",
    "    np.save(os.path.join('./StockData/TrainingData/','NormtrainingX_'+stock_name),Npdata)\n",
    "    print(path[12:21],\" trainX  \",Npdata.shape)\n",
    "    #print(Npdata)\n",
    "    Npdata=scaler.transform(resha(x_test))# normalize x_test with scale of train_x\n",
    "    np.save(os.path.join('./StockData/TrainingData/','NormtestingX_'+stock_name),Npdata)\n",
    "    print(path[12:21],\" testX  \",Npdata.shape)\n",
    "    #print(Npdata)\n",
    "    \n",
    "    Npdata=np.array(train_y)\n",
    "    np.save(os.path.join('./StockData/TrainingData/','trainingY_'+stock_name),Npdata)\n",
    "    print(path[12:21],\" trainY  \",Npdata.shape)\n",
    "    #print(Npdata)\n",
    "    \n",
    "    Npdata=np.array(y_test)\n",
    "    np.save(os.path.join('./StockData/TrainingData/','testingY_'+stock_name),Npdata)\n",
    "    print(path[12:21],\" testY  \",Npdata.shape)\n",
    "    #print(Npdata)\n",
    "    \n",
    "\n",
    "def add_MA5(data):\n",
    "    close=data.loc[ : ,'close'].values.tolist()\n",
    "    ma5=[]\n",
    "    for i in range(0,len(close)):\n",
    "        if i>=4:\n",
    "            ma5.append(sum(data.loc[ i-4 : i ,'close'].values.tolist())/5)\n",
    "        else:\n",
    "            ma5.append(0)\n",
    "    return ma5\n",
    "\n",
    "def add_MA20(data):\n",
    "    close=data.loc[ : ,'close'].values.tolist()\n",
    "    ma20=[]\n",
    "    for i in range(0,len(close)):\n",
    "        if i>=20:\n",
    "            ma20.append(sum(data.loc[ i-20 : i ,'close'].values.tolist())/20)\n",
    "        else:\n",
    "            ma20.append(0)\n",
    "    return ma20\n",
    "\n",
    "def add_MA60(data):\n",
    "    close=data.loc[ : ,'close'].values.tolist()\n",
    "    ma60=[]\n",
    "    for i in range(0,len(close)):\n",
    "        if i>=60:\n",
    "            ma60.append(sum(data.loc[ i-60 : i ,'close'].values.tolist())/60)\n",
    "        else:\n",
    "            ma60.append(0)\n",
    "    return ma60\n",
    "\n",
    "def add_rsv(data): # rsv (今天收盤-最近9天的最低價)/(最近9天的最高價-最近9天的最低價)\n",
    "    rsv=[]\n",
    "    close=data.loc[ : ,'close'].values.tolist() \n",
    "    for i in range(0,len(close)):\n",
    "        if i>=8:\n",
    "            low=min(data.loc[ i-8 : i ,'low'].values.tolist())\n",
    "            high=max(data.loc[ i-8 : i ,'high'].values.tolist()) \n",
    "            rsv.append(((close[i]-low)/(high-low))*100)\n",
    "        else:\n",
    "            rsv.append(0) \n",
    "    return rsv\n",
    "\n",
    "def add_k(data):  # k (2/3昨日K 加 1/3 今日rsv)\n",
    "    k=[] \n",
    "    rsv=data.loc[ : ,'rsv'].values.tolist() \n",
    "    for i in range(0,len(rsv)):\n",
    "        if i>=1:\n",
    "            k.append(((2/3)*k[i-1])+((1/3)*rsv[i]))\n",
    "        else:\n",
    "            k.append(rsv[0])       \n",
    "    return k\n",
    "\n",
    "def add_d(data): # d (2/3昨日d 加 1/3 今日k)\n",
    "    d=[]\n",
    "    k=data.loc[ : ,'k'].values.tolist() \n",
    "    for i in range(0,len(k)):\n",
    "        if i>=1:\n",
    "            d.append(((2/3)*d[i-1])+((1/3)*k[i]))\n",
    "        else:\n",
    "            d.append(k[0])            \n",
    "    return d\n",
    "\n",
    "def generate_train(close_type,feature,data):\n",
    "    train_x=[]\n",
    "    train_y=[]\n",
    "    for tmp in data:\n",
    "        # print(tmp[1])\n",
    "        i=tmp[1].dropna()\n",
    "        if len(i)==5: #Decide the way seperate the stock data\n",
    "            train_x.append(i.loc[ : ,feature].values.tolist())\n",
    "            #print(train_x)\n",
    "            Open=i.loc[ : ,'open'].values.tolist()[0]\n",
    "            Close=i.loc[ : ,close_type].values.tolist()[len(i.loc[ : ,close_type].values.tolist())-1]\n",
    "            train_y.append(float(\"%.2f\" %((Close-Open))))\n",
    "        else:\n",
    "            continue\n",
    "    #print(train_y)\n",
    "    #exit()\n",
    "    save_np(train_x,train_y)\n",
    "\n",
    "feature=input(\"Enter the needed features seperated with space: \").split(\" \")\n",
    "ctype=input(\"Enter the close type: \")\n",
    "resam=input(\"Enter the desired  data span , d  for day  w  for week  m  for month: \")\n",
    "\n",
    "for path in glob.glob(r'./StockData/stock0050.csv'):\n",
    "    csv_data=pd.DataFrame(pd.read_csv(path))\n",
    "    csv_data['date']=pd.to_datetime(csv_data['date'])\n",
    "    csv_data=csv_data.drop([0],axis=0)#drop 第一天 因為stockdata 有16年跳到17年的問題\n",
    "    \n",
    "    csv_data['rsv']=add_rsv(csv_data)\n",
    "    csv_data['k']=add_k(csv_data)\n",
    "    csv_data['d']=add_d(csv_data)\n",
    "    csv_data['ma5']=add_MA5(csv_data)\n",
    "    csv_data['ma20']=add_MA20(csv_data)\n",
    "    csv_data['ma60']=add_MA60(csv_data)\n",
    "    \n",
    "    print(csv_data)\n",
    "    csv_data=csv_data.set_index('date').resample(resam)#group\n",
    "    generate_train(ctype,feature,csv_data)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
